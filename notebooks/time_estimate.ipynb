{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import argparse\n",
    "#import os\n",
    "#import random\n",
    "#import time\n",
    "#import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#import torch.nn.parallel\n",
    "import torch.optim\n",
    "#iimport torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "#import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, filenames, labels, tranform):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.transform = tranform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Y = self.labels[index]\n",
    "        cv_in = cv2.imread(self.filenames[index]) # color\n",
    "        #if cv_in is None:\n",
    "            #print('input: '+self.filenames[ID])\n",
    "        #if cv_out is None:\n",
    "            #print('output: '+self.filenames[ID])\n",
    "        pil_in = Image.fromarray(cv_in)\n",
    "        X = self.transform(pil_in)\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader,model,criterion,optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    epoch_samples = 0\n",
    "    for x, y in train_loader:\n",
    "        epoch_samples += x.size(0)\n",
    "        y = y.float()\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "\n",
    "        x_var = torch.autograd.Variable(x)\n",
    "        y_var = torch.autograd.Variable(y)\n",
    "\n",
    "        yhat = model(x_var)\n",
    "        loss = criterion(yhat.squeeze(),y_var)\n",
    "        total_loss += loss.data.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return (total_loss/epoch_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(val_loader,model,criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    epoch_samples = 0\n",
    "    #with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        epoch_samples += x.size(0)\n",
    "        y = y.float()\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "\n",
    "        x_var = torch.autograd.Variable(x)\n",
    "        y_var = torch.autograd.Variable(y)\n",
    "\n",
    "        yhat = model(x_var)\n",
    "        loss = criterion(yhat.squeeze(),y_var)\n",
    "        total_loss += loss.data.item()\n",
    "\n",
    "    return (total_loss/epoch_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, MSE train set: 7.62194426\n",
      "Epoch: 1, MSE val set: 7.12528823\n",
      "\n",
      "Epoch: 2, MSE train set: 7.01334652\n",
      "Epoch: 2, MSE val set: 7.07455646\n",
      "\n",
      "Epoch: 3, MSE train set: 6.98098676\n",
      "Epoch: 3, MSE val set: 6.95733151\n",
      "\n",
      "Epoch: 4, MSE train set: 6.97745884\n",
      "Epoch: 4, MSE val set: 7.06214844\n",
      "\n",
      "Epoch: 5, MSE train set: 6.98333653\n",
      "Epoch: 5, MSE val set: 7.02035061\n",
      "\n",
      "Epoch: 6, MSE train set: 6.96900807\n",
      "Epoch: 6, MSE val set: 7.09079566\n",
      "\n",
      "Epoch: 7, MSE train set: 6.97882871\n",
      "Epoch: 7, MSE val set: 6.99961192\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4234c12aedff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: %d, MSE train set: %.8f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e2568377c370>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mepoch_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ab9738/chest/env_chest/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ab9738/chest/env_chest/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/ab9738/chest/env_chest/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"../mirflickr1m/labels.json\", \"r\") as file:\n",
    "    labels_dict = json.load(file)\n",
    "filenames = list(labels_dict.keys())\n",
    "labels = list(labels_dict.values())\n",
    "df_dict = {'filename': filenames, 'label': labels}\n",
    "# data = pd.read_csv('../final_data.csv')\n",
    "data = pd.DataFrame(df_dict)\n",
    "data_train = data.sample(frac=0.8,random_state=17)\n",
    "data_val = data.loc[~data.index.isin(data_train.index)]\n",
    "files_train = list(data_train['filename'])\n",
    "files_val = list(data_val['filename'])\n",
    "label_train = list(data_train['label'])\n",
    "label_val = list(data_val['label'])\n",
    "# ids_train = [i for i in range(len(files_train))]\n",
    "# ids_val = [i for i in range(len(files_val))]\n",
    "data = None\n",
    "data_train = None\n",
    "data_val = None\n",
    "model = models.resnet50()\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 10),\n",
    "                                      nn.ReLU(inplace=True),\n",
    "                                      nn.Linear(10,1))\n",
    "model = torch.nn.DataParallel(model).cuda()\n",
    "# model.load_state_dict(torch.load(\"model_hazy_best.pth\"),strict=False) # on GPU\n",
    "criterion = nn.MSELoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "train_dataset = TimeDataset(files_train, label_train,\n",
    "                            transforms.Compose([transforms.Resize((256,256)),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(mean=[0.5231, 0.5180, 0.5115],\n",
    "                                                                     std=[0.2014, 0.2018, 0.2100]),])) # normalize\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=8)\n",
    "val_dataset = TimeDataset(files_val, label_val,\n",
    "                          transforms.Compose([transforms.Resize((256,256)),\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize(mean=[0.5231, 0.5180, 0.5115],\n",
    "                                                                   std=[0.2014, 0.2018, 0.2100]),]))\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=8)\n",
    "\n",
    "best_loss = 1e5\n",
    "for epoch in range(10):\n",
    "    train_loss = train(train_loader,model,criterion,optimizer)\n",
    "    val_loss = val(val_loader,model,criterion)\n",
    "    print('Epoch: %d, MSE train set: %.8f' % (epoch+1, train_loss))\n",
    "    print('Epoch: %d, MSE val set: %.8f\\n' % (epoch+1, val_loss))\n",
    "#     if val_loss < best_loss:\n",
    "#         torch.save(model.state_dict(),'time_model_best_5e3.pth')\n",
    "#         best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
